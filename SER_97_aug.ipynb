{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba4b353",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a74787",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:11.240223Z",
     "iopub.status.busy": "2023-07-01T21:58:11.239332Z",
     "iopub.status.idle": "2023-07-01T21:58:18.629235Z",
     "shell.execute_reply": "2023-07-01T21:58:18.626615Z"
    },
    "papermill": {
     "duration": 7.421986,
     "end_time": "2023-07-01T21:58:18.631707",
     "exception": false,
     "start_time": "2023-07-01T21:58:11.209721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORT THE LIBRARIES\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music.\n",
    "# It can be used to extract the data from the audio files.\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn tools\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To play the audio files\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Sequences / text preprocessing (correct imports!)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Other keras layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, BatchNormalization, GRU\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Add Attention layers for improved architecture\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D\n",
    "\n",
    "# For saving/loading features\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Suppress warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "print(\"‚úÖ Imports done. TensorFlow version:\", tf.__version__)\n",
    "print(\"‚úÖ Additional imports: Attention layers, joblib for feature saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîá COMPREHENSIVE WARNING SUPPRESSION\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Suppress specific warnings that are common during audio processing\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"librosa\")\n",
    "#warnings.filterwarnings(\"ignore\", message=\".*n_fft.*too large.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*PySoundFile failed.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set environment variable to suppress TensorFlow warnings (if needed)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"‚úÖ Imports done. TensorFlow version:\", tf.__version__)\n",
    "print(\"‚úÖ Additional imports: Attention layers, joblib for feature saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878aff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÔøΩ Verify Kaggle Input Datasets\n",
    "print(\" Verifying available datasets in Kaggle environment...\")\n",
    "\n",
    "import os\n",
    "\n",
    "# Check available datasets in Kaggle input directory\n",
    "kaggle_input = \"/kaggle/input\"\n",
    "if os.path.exists(kaggle_input):\n",
    "    available_datasets = os.listdir(kaggle_input)\n",
    "    print(f\"‚úÖ Available datasets: {available_datasets}\")\n",
    "    \n",
    "    # Check each expected dataset\n",
    "    expected_datasets = [\n",
    "        \"ravdess-emotional-speech-audio\",\n",
    "        \"cremad\", \n",
    "        \"toronto-emotional-speech-set-tess\",\n",
    "        \"surrey-audiovisual-expressed-emotion-savee\"\n",
    "    ]\n",
    "    \n",
    "    for dataset in expected_datasets:\n",
    "        if dataset in available_datasets:\n",
    "            print(f\"‚úÖ {dataset}: Found\")\n",
    "        else:\n",
    "            print(f\"‚ùå {dataset}: Missing - Please add this dataset to your Kaggle notebook\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚ùå /kaggle/input directory not found. Make sure you're running on Kaggle.\")\n",
    "\n",
    "print(\"\\nÔøΩ Dataset paths for processing:\")\n",
    "print(\"RAVDESS: /kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\")\n",
    "print(\"CREMA: /kaggle/input/cremad/AudioWAV/\")  \n",
    "print(\"TESS: /kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data/\")\n",
    "print(\"SAVEE: /kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ad695",
   "metadata": {
    "papermill": {
     "duration": 0.039096,
     "end_time": "2023-07-01T21:58:26.065762",
     "exception": false,
     "start_time": "2023-07-01T21:58:26.026666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6d486",
   "metadata": {
    "papermill": {
     "duration": 0.03824,
     "end_time": "2023-07-01T21:58:26.142864",
     "exception": false,
     "start_time": "2023-07-01T21:58:26.104624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "                                              Ravdess Dataframe\n",
    "Here is the filename identifiers as per the official RAVDESS website:\n",
    "\n",
    "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "* Vocal channel (01 = speech, 02 = song).\n",
    "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4 This means the meta data for the audio file is:\n",
    "\n",
    "* Video-only (02)\n",
    "* Speech (01)\n",
    "* Fearful (06)\n",
    "* Normal intensity (01)\n",
    "* Statement \"dogs\" (02)\n",
    "* 1st Repetition (01)\n",
    "* 12th Actor (12) - Female (as the actor ID number is even)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae4870",
   "metadata": {
    "papermill": {
     "duration": 0.038859,
     "end_time": "2023-07-01T21:58:26.404767",
     "exception": false,
     "start_time": "2023-07-01T21:58:26.365908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba5069",
   "metadata": {
    "papermill": {
     "duration": 0.041605,
     "end_time": "2023-07-01T21:58:26.485375",
     "exception": false,
     "start_time": "2023-07-01T21:58:26.443770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Ravdees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12533b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path using local storage (faster processing)\n",
    "ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
    "ravdess_directory_list = os.listdir(ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "# Loop over actor folders\n",
    "for actor_dir in ravdess_directory_list:\n",
    "    actor_path = os.path.join(ravdess, actor_dir)\n",
    "    for file in os.listdir(actor_path):\n",
    "        part = file.split('.')[0].split('-')\n",
    "        emotion_code = int(part[2])\n",
    "        file_emotion.append(emotion_code)\n",
    "        file_path.append(os.path.join(actor_path, file))\n",
    "\n",
    "# Create dataframe\n",
    "ravdess_df = pd.DataFrame({\n",
    "    'Emotions': file_emotion,\n",
    "    'Path': file_path\n",
    "})\n",
    "\n",
    "# Map emotion codes to emotion labels\n",
    "ravdess_df['Emotions'] = ravdess_df['Emotions'].replace({\n",
    "    1: 'neutral',\n",
    "    2: 'neutral',\n",
    "    3: 'happy',\n",
    "    4: 'sad',\n",
    "    5: 'angry',\n",
    "    6: 'fear',\n",
    "    7: 'disgust',\n",
    "    8: 'surprise'\n",
    "})\n",
    "\n",
    "# Quick check\n",
    "print(ravdess_df.head())\n",
    "print(\"______________________________________________\")\n",
    "print(ravdess_df.tail())\n",
    "print(\"_______________________________________________\")\n",
    "print(ravdess_df['Emotions'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eaf9a0",
   "metadata": {
    "papermill": {
     "duration": 0.028091,
     "end_time": "2023-07-01T21:58:27.159176",
     "exception": false,
     "start_time": "2023-07-01T21:58:27.131085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Crema DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6caeb25",
   "metadata": {
    "papermill": {
     "duration": 0.028413,
     "end_time": "2023-07-01T21:58:27.215938",
     "exception": false,
     "start_time": "2023-07-01T21:58:27.187525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CREMA-D is a data set of 7,442 original clips from 91 actors. These clips were from 48 male and 43 female actors between the ages of 20 and 74 coming from a variety of races and ethnicities (African America, Asian, Caucasian, Hispanic, and Unspecified). Actors spoke from a selection of 12 sentences. The sentences were presented using one of six different emotions (Anger, Disgust, Fear, Happy, Neutral, and Sad) and four different emotion levels (Low, Medium, High, and Unspecified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35a002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:27.275432Z",
     "iopub.status.busy": "2023-07-01T21:58:27.274484Z",
     "iopub.status.idle": "2023-07-01T21:58:27.626451Z",
     "shell.execute_reply": "2023-07-01T21:58:27.625047Z"
    },
    "papermill": {
     "duration": 0.384579,
     "end_time": "2023-07-01T21:58:27.628914",
     "exception": false,
     "start_time": "2023-07-01T21:58:27.244335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to CREMA dataset using local storage (faster processing)\n",
    "Crema = \"/kaggle/input/cremad/AudioWAV/\"\n",
    "\n",
    "# Get list of all audio files\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "\n",
    "    # storing file emotions\n",
    "    part = file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "\n",
    "# Create dataframe\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "# Show summary\n",
    "print(Crema_df.head())\n",
    "print(Crema_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae30d6",
   "metadata": {
    "papermill": {
     "duration": 0.02909,
     "end_time": "2023-07-01T21:58:27.686675",
     "exception": false,
     "start_time": "2023-07-01T21:58:27.657585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TESS dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86e1f4",
   "metadata": {
    "papermill": {
     "duration": 0.028422,
     "end_time": "2023-07-01T21:58:27.744651",
     "exception": false,
     "start_time": "2023-07-01T21:58:27.716229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are a set of 200 target words were spoken in the carrier phrase \"Say the word _' by two actresses (aged 26 and 64 years) and recordings were made of the set portraying each of seven emotions (anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral). There are 2800 data points (audio files) in total.\n",
    "\n",
    "The dataset is organised such that each of the two female actor and their emotions are contain within its own folder. And within that, all 200 target words audio file can be found. The format of the audio file is a WAV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08917208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:27.804843Z",
     "iopub.status.busy": "2023-07-01T21:58:27.804223Z",
     "iopub.status.idle": "2023-07-01T21:58:28.553725Z",
     "shell.execute_reply": "2023-07-01T21:58:28.552135Z"
    },
    "papermill": {
     "duration": 0.782822,
     "end_time": "2023-07-01T21:58:28.556406",
     "exception": false,
     "start_time": "2023-07-01T21:58:27.773584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to dataset using local storage (faster processing)\n",
    "Tess = \"/kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data/\"\n",
    "\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part == 'ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "\n",
    "# DataFrame for emotions\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# DataFrame for paths\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "print(Tess_df.head())\n",
    "print(Tess_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1aa55c",
   "metadata": {
    "papermill": {
     "duration": 0.030963,
     "end_time": "2023-07-01T21:58:28.616889",
     "exception": false,
     "start_time": "2023-07-01T21:58:28.585926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**SAVEE Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132299c",
   "metadata": {
    "papermill": {
     "duration": 0.028353,
     "end_time": "2023-07-01T21:58:28.673755",
     "exception": false,
     "start_time": "2023-07-01T21:58:28.645402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Context\n",
    "The SAVEE database was recorded from four native English male speakers (identified as DC, JE, JK, KL), postgraduate students and researchers at the University of Surrey aged from 27 to 31 years. Emotion has been described psychologically in discrete categories: anger, disgust, fear, happiness, sadness and surprise. This is supported by the cross-cultural studies of Ekman [6] and studies of automatic emotion recognition tended to focus on recognizing these [12]. We added neutral to provide recordings of 7 emotion categories. The text material consisted of 15 TIMIT sentences per emotion: 3 common, 2 emotion-specific and 10 generic sentences that were different for each emotion and phonetically-balanced. The 3 common and 2 √ó 6 = 12 emotion-specific sentences were recorded as neutral to give 30 neutral sentences.\n",
    "\n",
    "Content\n",
    "This results in a total of 120 utterances per speaker, for example:\n",
    "\n",
    "Common: She had your dark suit in greasy wash water all year.\n",
    "Anger: Who authorized the unlimited expense account?\n",
    "Disgust: Please take this dirty table cloth to the cleaners for me.\n",
    "Fear: Call an ambulance for medical assistance.\n",
    "Happiness: Those musicians harmonize marvelously.\n",
    "Sadness: The prospect of cutting back spending is an unpleasant one for any governor.\n",
    "Surprise: The carpet cleaners shampooed our oriental rug.\n",
    "Neutral: The best way to learn is to solve extra problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9a901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:28.734188Z",
     "iopub.status.busy": "2023-07-01T21:58:28.732538Z",
     "iopub.status.idle": "2023-07-01T21:58:28.867431Z",
     "shell.execute_reply": "2023-07-01T21:58:28.865858Z"
    },
    "papermill": {
     "duration": 0.167293,
     "end_time": "2023-07-01T21:58:28.869797",
     "exception": false,
     "start_time": "2023-07-01T21:58:28.702504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Savee = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\"\n",
    "\n",
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(Savee + file)\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "print(Savee_df.head())\n",
    "print(Savee_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837aa17c",
   "metadata": {
    "papermill": {
     "duration": 0.028687,
     "end_time": "2023-07-01T21:58:28.927193",
     "exception": false,
     "start_time": "2023-07-01T21:58:28.898506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Integration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f12b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:28.986977Z",
     "iopub.status.busy": "2023-07-01T21:58:28.986031Z",
     "iopub.status.idle": "2023-07-01T21:58:29.057578Z",
     "shell.execute_reply": "2023-07-01T21:58:29.056474Z"
    },
    "papermill": {
     "duration": 0.104411,
     "end_time": "2023-07-01T21:58:29.060521",
     "exception": false,
     "start_time": "2023-07-01T21:58:28.956110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating Dataframe using all the 4 dataframes we created so far.\n",
    "data_path = pd.concat([ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed814307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:29.120616Z",
     "iopub.status.busy": "2023-07-01T21:58:29.119640Z",
     "iopub.status.idle": "2023-07-01T21:58:29.128519Z",
     "shell.execute_reply": "2023-07-01T21:58:29.127285Z"
    },
    "papermill": {
     "duration": 0.04099,
     "end_time": "2023-07-01T21:58:29.130684",
     "exception": false,
     "start_time": "2023-07-01T21:58:29.089694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data_path.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aabf08",
   "metadata": {
    "papermill": {
     "duration": 0.029086,
     "end_time": "2023-07-01T21:58:29.188793",
     "exception": false,
     "start_time": "2023-07-01T21:58:29.159707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">*                           Data Visualisation and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b2ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:29.249568Z",
     "iopub.status.busy": "2023-07-01T21:58:29.248691Z",
     "iopub.status.idle": "2023-07-01T21:58:29.521063Z",
     "shell.execute_reply": "2023-07-01T21:58:29.520049Z"
    },
    "papermill": {
     "duration": 0.305511,
     "end_time": "2023-07-01T21:58:29.523709",
     "exception": false,
     "start_time": "2023-07-01T21:58:29.218198",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(data_path.Emotions)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562f633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:29.586132Z",
     "iopub.status.busy": "2023-07-01T21:58:29.585778Z",
     "iopub.status.idle": "2023-07-01T21:58:31.225645Z",
     "shell.execute_reply": "2023-07-01T21:58:31.224212Z"
    },
    "papermill": {
     "duration": 1.673693,
     "end_time": "2023-07-01T21:58:31.228269",
     "exception": false,
     "start_time": "2023-07-01T21:58:29.554576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data,sr = librosa.load(file_path[0])\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acba22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:31.291693Z",
     "iopub.status.busy": "2023-07-01T21:58:31.291343Z",
     "iopub.status.idle": "2023-07-01T21:58:31.314448Z",
     "shell.execute_reply": "2023-07-01T21:58:31.313465Z"
    },
    "papermill": {
     "duration": 0.059365,
     "end_time": "2023-07-01T21:58:31.318773",
     "exception": false,
     "start_time": "2023-07-01T21:58:31.259408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069d348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:31.384732Z",
     "iopub.status.busy": "2023-07-01T21:58:31.384425Z",
     "iopub.status.idle": "2023-07-01T21:58:31.777841Z",
     "shell.execute_reply": "2023-07-01T21:58:31.776950Z"
    },
    "papermill": {
     "duration": 0.428919,
     "end_time": "2023-07-01T21:58:31.780053",
     "exception": false,
     "start_time": "2023-07-01T21:58:31.351134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE LOG MEL SPECTROGRAM\n",
    "plt.figure(figsize=(10, 5))\n",
    "spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \n",
    "log_spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(log_spectrogram, y_axis='mel', sr=sr, x_axis='time');\n",
    "plt.title('Mel Spectrogram ')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22105f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:31.850882Z",
     "iopub.status.busy": "2023-07-01T21:58:31.850102Z",
     "iopub.status.idle": "2023-07-01T21:58:32.154912Z",
     "shell.execute_reply": "2023-07-01T21:58:32.153948Z"
    },
    "papermill": {
     "duration": 0.342563,
     "end_time": "2023-07-01T21:58:32.157210",
     "exception": false,
     "start_time": "2023-07-01T21:58:31.814647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=30)\n",
    "\n",
    "\n",
    "# MFCC\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48242b",
   "metadata": {
    "papermill": {
     "duration": 0.037215,
     "end_time": "2023-07-01T21:58:32.232499",
     "exception": false,
     "start_time": "2023-07-01T21:58:32.195284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e509d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:32.309119Z",
     "iopub.status.busy": "2023-07-01T21:58:32.308708Z",
     "iopub.status.idle": "2023-07-01T21:58:32.316805Z",
     "shell.execute_reply": "2023-07-01T21:58:32.315864Z"
    },
    "papermill": {
     "duration": 0.049409,
     "end_time": "2023-07-01T21:58:32.319205",
     "exception": false,
     "start_time": "2023-07-01T21:58:32.269796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOISE\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# STRETCH\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "# SHIFT\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "# PITCH\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e08b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:32.395731Z",
     "iopub.status.busy": "2023-07-01T21:58:32.394851Z",
     "iopub.status.idle": "2023-07-01T21:58:32.812028Z",
     "shell.execute_reply": "2023-07-01T21:58:32.811070Z"
    },
    "papermill": {
     "duration": 0.458052,
     "end_time": "2023-07-01T21:58:32.814399",
     "exception": false,
     "start_time": "2023-07-01T21:58:32.356347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NORMAL AUDIO\n",
    "\n",
    "\n",
    "import librosa.display\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=data, sr=sr)\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8f8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:32.900486Z",
     "iopub.status.busy": "2023-07-01T21:58:32.899829Z",
     "iopub.status.idle": "2023-07-01T21:58:33.331253Z",
     "shell.execute_reply": "2023-07-01T21:58:33.330272Z"
    },
    "papermill": {
     "duration": 0.477332,
     "end_time": "2023-07-01T21:58:33.333535",
     "exception": false,
     "start_time": "2023-07-01T21:58:32.856203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AUDIO WITH NOISE\n",
    "x = noise(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d710ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:33.426343Z",
     "iopub.status.busy": "2023-07-01T21:58:33.425686Z",
     "iopub.status.idle": "2023-07-01T21:58:34.311854Z",
     "shell.execute_reply": "2023-07-01T21:58:34.310892Z"
    },
    "papermill": {
     "duration": 0.935507,
     "end_time": "2023-07-01T21:58:34.314143",
     "exception": false,
     "start_time": "2023-07-01T21:58:33.378636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STRETCHED AUDIO\n",
    "x = stretch(data)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb3848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:34.417092Z",
     "iopub.status.busy": "2023-07-01T21:58:34.416062Z",
     "iopub.status.idle": "2023-07-01T21:58:34.835821Z",
     "shell.execute_reply": "2023-07-01T21:58:34.834670Z"
    },
    "papermill": {
     "duration": 0.474343,
     "end_time": "2023-07-01T21:58:34.839092",
     "exception": false,
     "start_time": "2023-07-01T21:58:34.364749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SHIFTED AUDIO\n",
    "x = shift(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537b9ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:34.948499Z",
     "iopub.status.busy": "2023-07-01T21:58:34.948117Z",
     "iopub.status.idle": "2023-07-01T21:58:35.475808Z",
     "shell.execute_reply": "2023-07-01T21:58:35.474710Z"
    },
    "papermill": {
     "duration": 0.58569,
     "end_time": "2023-07-01T21:58:35.478918",
     "exception": false,
     "start_time": "2023-07-01T21:58:34.893228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AUDIO WITH PITCH\n",
    "x = pitch(data, sr)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442fb0f",
   "metadata": {
    "papermill": {
     "duration": 0.057118,
     "end_time": "2023-07-01T21:58:35.593863",
     "exception": false,
     "start_time": "2023-07-01T21:58:35.536745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14d7c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:35.713872Z",
     "iopub.status.busy": "2023-07-01T21:58:35.712859Z",
     "iopub.status.idle": "2023-07-01T21:58:35.726973Z",
     "shell.execute_reply": "2023-07-01T21:58:35.726045Z"
    },
    "papermill": {
     "duration": 0.075607,
     "end_time": "2023-07-01T21:58:35.729284",
     "exception": false,
     "start_time": "2023-07-01T21:58:35.653677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(y=data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    \"\"\"Extract features with consistent dimensions\"\"\"\n",
    "    result=np.array([])\n",
    "    \n",
    "    # Spectral features for better emotion recognition\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=data, sr=sr, hop_length=hop_length)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=data, sr=sr, hop_length=hop_length)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=data, sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Extract individual features\n",
    "    zcr_feat = zcr(data,frame_length,hop_length)\n",
    "    rmse_feat = rmse(data,frame_length,hop_length)\n",
    "    mfcc_feat = mfcc(data,sr,frame_length,hop_length)\n",
    "    \n",
    "    # Debug: Check individual feature shapes\n",
    "    debug = False  # Set to True for debugging\n",
    "    if debug:\n",
    "        print(f\"ZCR shape: {zcr_feat.shape}, RMSE shape: {rmse_feat.shape}\")\n",
    "        print(f\"MFCC shape: {mfcc_feat.shape}\")\n",
    "        print(f\"Spectral shapes: {np.squeeze(spectral_centroid).shape}, {np.squeeze(spectral_bandwidth).shape}, {np.squeeze(spectral_rolloff).shape}\")\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      zcr_feat,\n",
    "                      rmse_feat,\n",
    "                      mfcc_feat,\n",
    "                      np.squeeze(spectral_centroid),\n",
    "                      np.squeeze(spectral_bandwidth),\n",
    "                      np.squeeze(spectral_rolloff)\n",
    "                     ))\n",
    "    \n",
    "    # Ensure result is always 1D\n",
    "    result = np.ravel(result)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Final feature shape: {result.shape}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ecdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified function to extract only original features (no augmentation)\n",
    "def get_original_features(path, duration=2.5, offset=0.6):\n",
    "    \"\"\"Extract features from original audio without augmentation\"\"\"\n",
    "    data, sr = librosa.load(path, duration=duration, offset=offset)\n",
    "    features = extract_features(data)\n",
    "    return np.array(features)\n",
    "\n",
    "# Function to extract augmented features (for training data only)\n",
    "def get_augmented_features(path, duration=2.5, offset=0.6):\n",
    "    \"\"\"Extract features with augmentation - use only for training data\"\"\"\n",
    "    data, sr = librosa.load(path, duration=duration, offset=offset)\n",
    "    \n",
    "    # Original features\n",
    "    aud_original = extract_features(data)\n",
    "    audio = np.array(aud_original)\n",
    "    \n",
    "    # Augmented features\n",
    "    noised_audio = noise(data)\n",
    "    aud_noise = extract_features(noised_audio)\n",
    "    audio = np.vstack((audio, aud_noise))\n",
    "    \n",
    "    pitched_audio = pitch(data, sr)\n",
    "    aud_pitch = extract_features(pitched_audio)\n",
    "    audio = np.vstack((audio, aud_pitch))\n",
    "    \n",
    "    pitched_audio1 = pitch(data, sr)\n",
    "    pitched_noised_audio = noise(pitched_audio1)\n",
    "    aud_pitch_noise = extract_features(pitched_noised_audio)\n",
    "    audio = np.vstack((audio, aud_pitch_noise))\n",
    "    \n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982f78f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T21:58:35.847098Z",
     "iopub.status.busy": "2023-07-01T21:58:35.846728Z",
     "iopub.status.idle": "2023-07-01T21:58:35.852414Z",
     "shell.execute_reply": "2023-07-01T21:58:35.851279Z"
    },
    "papermill": {
     "duration": 0.06852,
     "end_time": "2023-07-01T21:58:35.854953",
     "exception": false,
     "start_time": "2023-07-01T21:58:35.786433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed83b8",
   "metadata": {
    "papermill": {
     "duration": 0.921275,
     "end_time": "2023-07-01T23:31:52.969542",
     "exception": false,
     "start_time": "2023-07-01T23:31:52.048267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Faster way to get features\n",
    "***Parallel way***\n",
    "\n",
    "\n",
    "Here's a breakdown of what the code does:\n",
    "\n",
    "The from joblib import Parallel, delayed statement imports the Parallel and delayed functions from the joblib library.\n",
    "The start = timeit.default_timer() statement starts a timer to measure the time taken to process the audio files.\n",
    "The process_feature function processes a single audio file by extracting its features using the get_feat function and appending the corresponding X and Y values to the X and Y lists.\n",
    "The paths and emotions variables extract the paths and emotions from the data_path DataFrame.\n",
    "The Parallel function runs the process_feature function in parallel for each audio file using the delayed function to wrap the process_feature function.\n",
    "The results variable contains the X and Y values for each audio file.\n",
    "The X and Y lists are populated with the X and Y values from each audio file using the extend method.\n",
    "The stop = timeit.default_timer() statement stops the timer.\n",
    "The print('Time: ', stop - start) statement prints the time taken to process the audio files.\n",
    "Overall, this code demonstrates how to use the joblib library to process multiple audio files in parallel, which can significantly reduce the processing time for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36154b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:31:56.810882Z",
     "iopub.status.busy": "2023-07-01T23:31:56.810509Z",
     "iopub.status.idle": "2023-07-01T23:31:56.819769Z",
     "shell.execute_reply": "2023-07-01T23:31:56.818746Z"
    },
    "papermill": {
     "duration": 1.000793,
     "end_time": "2023-07-01T23:31:56.822151",
     "exception": false,
     "start_time": "2023-07-01T23:31:55.821358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import timeit\n",
    "\n",
    "# First, extract only original features (no augmentation) to prevent data leakage\n",
    "start = timeit.default_timer()\n",
    "\n",
    "def process_original_feature(path, emotion):\n",
    "    \"\"\"Process original features without augmentation with error handling\"\"\"\n",
    "    try:\n",
    "        features = get_original_features(path)\n",
    "        # Debug: Check feature shape\n",
    "        if len(features.shape) != 1:\n",
    "            print(f\"‚ö†Ô∏è Warning: Features shape {features.shape} for {path}\")\n",
    "        return features, emotion, True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {path}: {e}\")\n",
    "        return None, emotion, False\n",
    "\n",
    "paths = data_path.Path\n",
    "emotions = data_path.Emotions\n",
    "\n",
    "print(\"Extracting original features without augmentation...\")\n",
    "print(f\"Total files to process: {len(paths)}\")\n",
    "\n",
    "# Run the loop in parallel for original features only\n",
    "results = Parallel(n_jobs=-1)(delayed(process_original_feature)(path, emotion) \n",
    "                              for (path, emotion) in zip(paths, emotions))\n",
    "\n",
    "# Collect the results with error handling\n",
    "X_original = []\n",
    "Y_original = []\n",
    "failed_files = []\n",
    "\n",
    "for result in results:\n",
    "    features, emotion, success = result\n",
    "    if success and features is not None:\n",
    "        X_original.append(features)\n",
    "        Y_original.append(emotion)\n",
    "    else:\n",
    "        failed_files.append((emotion, success))\n",
    "\n",
    "print(f\"‚úÖ Successfully processed: {len(X_original)} files\")\n",
    "print(f\"‚ùå Failed files: {len(failed_files)}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(\"Failed files info:\", failed_files[:5])  # Show first 5 failures\n",
    "\n",
    "# Check feature dimensions before conversion\n",
    "if X_original:\n",
    "    feature_lengths = [len(f) for f in X_original]\n",
    "    unique_lengths = set(feature_lengths)\n",
    "    print(f\"Feature dimensions found: {unique_lengths}\")\n",
    "    \n",
    "    if len(unique_lengths) > 1:\n",
    "        print(\"‚ö†Ô∏è INHOMOGENEOUS FEATURES DETECTED!\")\n",
    "        print(f\"Min length: {min(feature_lengths)}\")\n",
    "        print(f\"Max length: {max(feature_lengths)}\")\n",
    "        \n",
    "        # Fix: Use the most common length or pad/truncate\n",
    "        from collections import Counter\n",
    "        length_counts = Counter(feature_lengths)\n",
    "        target_length = length_counts.most_common(1)[0][0]\n",
    "        print(f\"Using target length: {target_length}\")\n",
    "        \n",
    "        # Pad or truncate features to target length\n",
    "        X_original_fixed = []\n",
    "        for features in X_original:\n",
    "            if len(features) < target_length:\n",
    "                # Pad with zeros\n",
    "                padded = np.pad(features, (0, target_length - len(features)), 'constant')\n",
    "                X_original_fixed.append(padded)\n",
    "            elif len(features) > target_length:\n",
    "                # Truncate\n",
    "                X_original_fixed.append(features[:target_length])\n",
    "            else:\n",
    "                X_original_fixed.append(features)\n",
    "        \n",
    "        X_original = X_original_fixed\n",
    "        print(f\"‚úÖ Fixed inhomogeneous features to length {target_length}\")\n",
    "\n",
    "# Convert to numpy array\n",
    "X_original = np.array(X_original)\n",
    "Y_original = np.array(Y_original)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(f'Time for original feature extraction: {stop - start:.2f} seconds')\n",
    "print(f'Original dataset shape: {X_original.shape}')\n",
    "print(f'Feature dimensions: {X_original.shape[1] if len(X_original.shape) > 1 else \"N/A\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç DEBUG: Test feature extraction on a single file first\n",
    "print(\"üîç Testing feature extraction on a single file...\")\n",
    "\n",
    "# Get the first file path for testing\n",
    "test_path = data_path.Path.iloc[0]\n",
    "test_emotion = data_path.Emotions.iloc[0]\n",
    "\n",
    "print(f\"Test file: {test_path}\")\n",
    "print(f\"Test emotion: {test_emotion}\")\n",
    "\n",
    "try:\n",
    "    # Test the feature extraction\n",
    "    features = get_original_features(test_path)\n",
    "    print(f\"‚úÖ Feature extraction successful!\")\n",
    "    print(f\"Feature shape: {features.shape}\")\n",
    "    print(f\"Feature length: {len(features)}\")\n",
    "    print(f\"Feature type: {type(features)}\")\n",
    "    print(f\"Sample features (first 10): {features[:10]}\")\n",
    "    \n",
    "    # Test on a few more files to check consistency\n",
    "    print(\"\\nüîç Testing on 5 files for consistency...\")\n",
    "    for i in range(min(5, len(data_path))):\n",
    "        path = data_path.Path.iloc[i]\n",
    "        try:\n",
    "            feat = get_original_features(path)\n",
    "            print(f\"File {i+1}: Shape {feat.shape}, Length {len(feat)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"File {i+1}: ERROR - {e}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in feature extraction: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32c307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:31:58.752586Z",
     "iopub.status.busy": "2023-07-01T23:31:58.752167Z",
     "iopub.status.idle": "2023-07-01T23:31:58.759161Z",
     "shell.execute_reply": "2023-07-01T23:31:58.758232Z"
    },
    "papermill": {
     "duration": 0.995293,
     "end_time": "2023-07-01T23:31:58.761200",
     "exception": false,
     "start_time": "2023-07-01T23:31:57.765907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the shape of our original dataset\n",
    "print(f\"Original features shape: {X_original.shape}\")\n",
    "print(f\"Original labels shape: {Y_original.shape}\")\n",
    "print(\"Emotion distribution:\", np.unique(Y_original, return_counts=True))\n",
    "\n",
    "# Perform train-test split on ORIGINAL data (no augmentation yet)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the original dataset\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(\n",
    "    X_original, Y_original, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True,\n",
    "    stratify=Y_original\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter train-test split (original data only):\")\n",
    "print(f\"Train set: {X_train_orig.shape}\")\n",
    "print(f\"Test set: {X_test_orig.shape}\")\n",
    "print(f\"Train labels: {y_train_orig.shape}\")\n",
    "print(f\"Test labels: {y_test_orig.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02018354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_augmented_training_feature(path, emotion):\n",
    "    \"\"\"Process augmented features for training data only\"\"\"\n",
    "    features = get_augmented_features(path)\n",
    "    emotions_list = [emotion] * features.shape[0]  # 4 copies for each augmentation\n",
    "    return features, emotions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified approach: Apply augmentation only to training data\n",
    "#-------------TEST\n",
    "print(\"Applying data augmentation to training set only...\")\n",
    "\n",
    "# Create train/test indices to map back to original dataset\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "# Since we split X_original and Y_original, we need to map back to data_path indices\n",
    "# We'll use the train_test_split indices directly\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the actual indices from the split\n",
    "indices = np.arange(len(X_original))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True,\n",
    "    stratify=Y_original\n",
    ")\n",
    "\n",
    "print(f\"Training indices: {len(train_idx)}\")\n",
    "print(f\"Testing indices: {len(test_idx)}\")\n",
    "\n",
    "# Extract training paths and emotions using indices\n",
    "train_paths = data_path.Path.iloc[train_idx].values\n",
    "train_emotions = data_path.Emotions.iloc[train_idx].values\n",
    "test_paths = data_path.Path.iloc[test_idx].values  \n",
    "test_emotions = data_path.Emotions.iloc[test_idx].values\n",
    "\n",
    "print(f\"Training paths: {len(train_paths)}\")\n",
    "print(f\"Training emotions: {len(train_emotions)}\")\n",
    "\n",
    "# Apply augmentation to training data only\n",
    "start_aug = timeit.default_timer()\n",
    "train_aug_results = Parallel(n_jobs=-1)(delayed(process_augmented_training_feature)(path, emotion) \n",
    "                                         for (path, emotion) in zip(train_paths, train_emotions))\n",
    "\n",
    "# Collect augmented training results  \n",
    "X_train_augmented = []\n",
    "y_train_augmented = []\n",
    "for features, emotions_list in train_aug_results:\n",
    "    for i in range(features.shape[0]):\n",
    "        X_train_augmented.append(features[i])\n",
    "        y_train_augmented.append(emotions_list[i])\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)\n",
    "\n",
    "# Test data - extract original features only (no augmentation)\n",
    "test_results = Parallel(n_jobs=-1)(delayed(process_original_feature)(path, emotion) \n",
    "                                   for (path, emotion) in zip(test_paths, test_emotions))\n",
    "\n",
    "X_test_final = []\n",
    "y_test_final = []\n",
    "for features, emotion in test_results:\n",
    "    X_test_final.append(features)\n",
    "    y_test_final.append(emotion)\n",
    "\n",
    "X_test_final = np.array(X_test_final)\n",
    "y_test_final = np.array(y_test_final)\n",
    "\n",
    "stop_aug = timeit.default_timer()\n",
    "print(f'Time for augmentation: {stop_aug - start_aug:.2f} seconds')\n",
    "\n",
    "print(f\"\\nFinal datasets (NO DATA LEAKAGE):\")\n",
    "print(f\"Training (with 4x augmentation): {X_train_augmented.shape}\")\n",
    "print(f\"Testing (original only): {X_test_final.shape}\")\n",
    "print(f\"Training labels: {y_train_augmented.shape}\")\n",
    "print(f\"Testing labels: {y_test_final.shape}\")\n",
    "\n",
    "# Set final variables\n",
    "X_train_final = X_train_augmented\n",
    "y_train_final = y_train_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04687951",
   "metadata": {
    "papermill": {
     "duration": 0.928271,
     "end_time": "2023-07-01T23:32:00.687697",
     "exception": false,
     "start_time": "2023-07-01T23:31:59.759426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f413459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SAVE EXTRACTED FEATURES FOR LATER USE\n",
    "# This allows you to do extraction and training in different Kaggle sessions\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create directory for saved features\n",
    "os.makedirs('/kaggle/working/extracted_features', exist_ok=True)\n",
    "\n",
    "print(\"üíæ Saving extracted features for future sessions...\")\n",
    "\n",
    "# Save the leak-free datasets\n",
    "feature_data = {\n",
    "    'X_train_augmented': X_train_augmented,\n",
    "    'y_train_augmented': y_train_augmented,\n",
    "    'X_test_final': X_test_final,\n",
    "    'y_test_final': y_test_final,\n",
    "    'train_idx': train_idx,\n",
    "    'test_idx': test_idx,\n",
    "    'label_encoder': label_encoder,\n",
    "    'onehot_encoder': onehot_encoder\n",
    "}\n",
    "\n",
    "# Save using joblib (efficient for numpy arrays)\n",
    "joblib.dump(feature_data, '/kaggle/working/extracted_features/leak_free_features.pkl')\n",
    "\n",
    "# Also save individual components for flexibility\n",
    "np.save('/kaggle/working/extracted_features/X_train_augmented.npy', X_train_augmented)\n",
    "np.save('/kaggle/working/extracted_features/y_train_augmented.npy', y_train_augmented)\n",
    "np.save('/kaggle/working/extracted_features/X_test_final.npy', X_test_final)\n",
    "np.save('/kaggle/working/extracted_features/y_test_final.npy', y_test_final)\n",
    "np.save('/kaggle/working/extracted_features/train_indices.npy', train_idx)\n",
    "np.save('/kaggle/working/extracted_features/test_indices.npy', test_idx)\n",
    "\n",
    "# Save encoders separately\n",
    "with open('/kaggle/working/extracted_features/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "with open('/kaggle/working/extracted_features/onehot_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(onehot_encoder, f)\n",
    "\n",
    "print(\"‚úÖ Features saved successfully!\")\n",
    "print(f\"üìÅ Saved files in: /kaggle/working/extracted_features/\")\n",
    "print(f\"üìä Training features: {X_train_augmented.shape}\")\n",
    "print(f\"üìä Test features: {X_test_final.shape}\")\n",
    "print(f\"üìä Training labels: {y_train_augmented.shape}\")\n",
    "print(f\"üìä Test labels: {y_test_final.shape}\")\n",
    "\n",
    "# Save metadata for verification\n",
    "metadata = {\n",
    "    'extraction_timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'original_dataset_size': len(data_path),\n",
    "    'train_size_augmented': len(X_train_augmented),\n",
    "    'test_size_original': len(X_test_final),\n",
    "    'feature_dimensions': X_train_augmented.shape[1],\n",
    "    'augmentation_factor': 4,\n",
    "    'classes': label_encoder.classes_.tolist(),\n",
    "    'train_test_split_ratio': 0.2,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "with open('/kaggle/working/extracted_features/metadata.json', 'w') as f:\n",
    "    import json\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Metadata saved for verification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf86bb0",
   "metadata": {},
   "source": [
    "## üîÑ LOAD EXTRACTED FEATURES (For New Sessions)\n",
    "**Use this section if you want to skip feature extraction and load pre-extracted features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3722f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ LOAD PRE-EXTRACTED FEATURES\n",
    "# Run this cell if you want to skip feature extraction and load saved features\n",
    "# Make sure the extracted_features folder exists in your Kaggle input or working directory\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_extracted_features(base_path='/kaggle/input/extracted-features'):\n",
    "    \"\"\"\n",
    "    Load pre-extracted features from a previous session\n",
    "    \n",
    "    Args:\n",
    "        base_path: Path to the extracted features directory\n",
    "                  For Kaggle datasets: '/kaggle/input/your-dataset-name'\n",
    "                  For working directory: '/kaggle/working/extracted_features'\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"‚ùå Features directory not found: {base_path}\")\n",
    "        print(\"üí° Make sure to:\")\n",
    "        print(\"   1. Save this notebook's output as a Kaggle dataset, OR\")\n",
    "        print(\"   2. Copy features from /kaggle/working/extracted_features to your input\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìÇ Loading features from: {base_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Method 1: Load complete feature data (recommended)\n",
    "        if os.path.exists(f\"{base_path}/leak_free_features.pkl\"):\n",
    "            print(\"üîÑ Loading complete feature dataset...\")\n",
    "            feature_data = joblib.load(f\"{base_path}/leak_free_features.pkl\")\n",
    "            \n",
    "            X_train_augmented = feature_data['X_train_augmented']\n",
    "            y_train_augmented = feature_data['y_train_augmented']\n",
    "            X_test_final = feature_data['X_test_final']\n",
    "            y_test_final = feature_data['y_test_final']\n",
    "            train_idx = feature_data['train_idx']\n",
    "            test_idx = feature_data['test_idx']\n",
    "            label_encoder = feature_data['label_encoder']\n",
    "            onehot_encoder = feature_data['onehot_encoder']\n",
    "            \n",
    "        else:\n",
    "            # Method 2: Load individual components\n",
    "            print(\"üîÑ Loading individual feature files...\")\n",
    "            X_train_augmented = np.load(f\"{base_path}/X_train_augmented.npy\")\n",
    "            y_train_augmented = np.load(f\"{base_path}/y_train_augmented.npy\")\n",
    "            X_test_final = np.load(f\"{base_path}/X_test_final.npy\")\n",
    "            y_test_final = np.load(f\"{base_path}/y_test_final.npy\")\n",
    "            train_idx = np.load(f\"{base_path}/train_indices.npy\")\n",
    "            test_idx = np.load(f\"{base_path}/test_indices.npy\")\n",
    "            \n",
    "            with open(f\"{base_path}/label_encoder.pkl\", 'rb') as f:\n",
    "                label_encoder = pickle.load(f)\n",
    "            with open(f\"{base_path}/onehot_encoder.pkl\", 'rb') as f:\n",
    "                onehot_encoder = pickle.load(f)\n",
    "        \n",
    "        # Load metadata for verification\n",
    "        if os.path.exists(f\"{base_path}/metadata.json\"):\n",
    "            with open(f\"{base_path}/metadata.json\", 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            print(\"üìã Metadata:\")\n",
    "            for key, value in metadata.items():\n",
    "                print(f\"   {key}: {value}\")\n",
    "        \n",
    "        print(\"‚úÖ Features loaded successfully!\")\n",
    "        print(f\"üìä Training features: {X_train_augmented.shape}\")\n",
    "        print(f\"üìä Test features: {X_test_final.shape}\")\n",
    "        print(f\"üìä Training labels: {y_train_augmented.shape}\")\n",
    "        print(f\"üìä Test labels: {y_test_final.shape}\")\n",
    "        print(f\"üìä Classes: {label_encoder.classes_}\")\n",
    "        \n",
    "        # Set global variables for use in training\n",
    "        globals()['X_train_final'] = X_train_augmented\n",
    "        globals()['y_train_final'] = y_train_augmented\n",
    "        globals()['X_test_final'] = X_test_final\n",
    "        globals()['y_test_final'] = y_test_final\n",
    "        globals()['label_encoder'] = label_encoder\n",
    "        globals()['onehot_encoder'] = onehot_encoder\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train_augmented,\n",
    "            'y_train': y_train_augmented,\n",
    "            'X_test': X_test_final,\n",
    "            'y_test': y_test_final,\n",
    "            'label_encoder': label_encoder,\n",
    "            'onehot_encoder': onehot_encoder\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading features: {e}\")\n",
    "        return None\n",
    "\n",
    "# Uncomment and run this line to load features:\n",
    "# loaded_data = load_extracted_features('/kaggle/input/your-dataset-name')\n",
    "\n",
    "print(\"üîß Function defined. To use:\")\n",
    "print(\"   loaded_data = load_extracted_features('/kaggle/input/your-dataset-name')\")\n",
    "print(\"   OR\")\n",
    "print(\"   loaded_data = load_extracted_features('/kaggle/working/extracted_features')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ QUICK START FOR NEW SESSIONS\n",
    "# Uncomment the appropriate line below to load your features:\n",
    "\n",
    "# Option 1: Load from working directory (same session)\n",
    "# loaded_data = load_extracted_features('/kaggle/working/extracted_features')\n",
    "\n",
    "# Option 2: Load from Kaggle dataset (new session)\n",
    "# loaded_data = load_extracted_features('/kaggle/input/your-dataset-name')\n",
    "\n",
    "# After loading, you can jump directly to the \"Data preparation\" section below\n",
    "# and skip all the feature extraction cells above\n",
    "\n",
    "print(\"üí° Instructions for new sessions:\")\n",
    "print(\"1. Save this notebook's output as a Kaggle dataset\")\n",
    "print(\"2. In new session, add that dataset as input\")\n",
    "print(\"3. Uncomment one of the load_extracted_features() lines above\")\n",
    "print(\"4. Skip to 'Data preparation' section\")\n",
    "print(\"5. Continue with model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555e34d",
   "metadata": {
    "papermill": {
     "duration": 1.020431,
     "end_time": "2023-07-01T23:36:18.189692",
     "exception": false,
     "start_time": "2023-07-01T23:36:17.169261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a137c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:20.171306Z",
     "iopub.status.busy": "2023-07-01T23:36:20.170885Z",
     "iopub.status.idle": "2023-07-01T23:36:21.007213Z",
     "shell.execute_reply": "2023-07-01T23:36:21.006056Z"
    },
    "papermill": {
     "duration": 1.891783,
     "end_time": "2023-07-01T23:36:21.010232",
     "exception": false,
     "start_time": "2023-07-01T23:36:19.118449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preparation using leak-free datasets\n",
    "print(\"Preparing data for modeling...\")\n",
    "\n",
    "# Use our leak-free datasets\n",
    "X = X_train_final  # Training features (with augmentation)\n",
    "Y = y_train_final  # Training labels (with augmentation)\n",
    "\n",
    "X_test = X_test_final  # Test features (original only)  \n",
    "Y_test = y_test_final  # Test labels (original only)\n",
    "\n",
    "print(f\"Training data: {X.shape}\")\n",
    "print(f\"Test data: {X_test.shape}\")\n",
    "print(f\"Training labels: {Y.shape}\")\n",
    "print(f\"Test labels: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc6f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:22.930711Z",
     "iopub.status.busy": "2023-07-01T23:36:22.930320Z",
     "iopub.status.idle": "2023-07-01T23:36:22.959022Z",
     "shell.execute_reply": "2023-07-01T23:36:22.958053Z"
    },
    "papermill": {
     "duration": 1.021984,
     "end_time": "2023-07-01T23:36:22.961334",
     "exception": false,
     "start_time": "2023-07-01T23:36:21.939350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-hot encode the labels (fit on training, transform both)\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# First encode to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_int = label_encoder.fit_transform(Y)\n",
    "y_test_int = label_encoder.transform(Y_test)\n",
    "\n",
    "# Then one-hot encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "Y_train_onehot = onehot_encoder.fit_transform(y_train_int.reshape(-1, 1))\n",
    "Y_test_onehot = onehot_encoder.transform(y_test_int.reshape(-1, 1))\n",
    "\n",
    "print(f\"One-hot encoded training labels shape: {Y_train_onehot.shape}\")\n",
    "print(f\"One-hot encoded test labels shape: {Y_test_onehot.shape}\")\n",
    "print(f\"Number of classes: {Y_train_onehot.shape[1]}\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b64ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:24.840986Z",
     "iopub.status.busy": "2023-07-01T23:36:24.839901Z",
     "iopub.status.idle": "2023-07-01T23:36:24.848297Z",
     "shell.execute_reply": "2023-07-01T23:36:24.847253Z"
    },
    "papermill": {
     "duration": 0.948197,
     "end_time": "2023-07-01T23:36:24.850397",
     "exception": false,
     "start_time": "2023-07-01T23:36:23.902200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final data preparation - NO additional train_test_split needed!\n",
    "# We already have leak-free train/test split\n",
    "\n",
    "# Assign final variables for modeling\n",
    "x_train = X  # Training features (with augmentation)\n",
    "x_test = X_test  # Test features (original only)\n",
    "y_train = Y_train_onehot  # One-hot encoded training labels\n",
    "y_test = Y_test_onehot  # One-hot encoded test labels\n",
    "\n",
    "print(f\"Final training set: {x_train.shape}\")\n",
    "print(f\"Final test set: {x_test.shape}\")\n",
    "print(f\"Final training labels: {y_train.shape}\")  \n",
    "print(f\"Final test labels: {y_test.shape}\")\n",
    "\n",
    "# Verify no data leakage\n",
    "print(f\"\\nData leakage check:\")\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Test samples: {len(x_test)}\")\n",
    "print(f\"Total original samples: {len(data_path)}\")\n",
    "print(f\"Expected training samples (with 4x augmentation): {len(data_path) * 0.8 * 4}\")\n",
    "print(f\"Expected test samples (no augmentation): {len(data_path) * 0.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17556703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:26.789686Z",
     "iopub.status.busy": "2023-07-01T23:36:26.788960Z",
     "iopub.status.idle": "2023-07-01T23:36:31.242841Z",
     "shell.execute_reply": "2023-07-01T23:36:31.241881Z"
    },
    "papermill": {
     "duration": 5.391928,
     "end_time": "2023-07-01T23:36:31.245218",
     "exception": false,
     "start_time": "2023-07-01T23:36:25.853290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"‚úÖ Using leak-free train/test split from above (no additional split needed)\")\n",
    "print(f\"Training data: {x_train.shape}\")\n",
    "print(f\"Test data: {x_test.shape}\")\n",
    "print(f\"Training labels: {y_train.shape}\")\n",
    "print(f\"Test labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4edea58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:35.134384Z",
     "iopub.status.busy": "2023-07-01T23:36:35.133766Z",
     "iopub.status.idle": "2023-07-01T23:36:37.687221Z",
     "shell.execute_reply": "2023-07-01T23:36:37.686264Z"
    },
    "papermill": {
     "duration": 3.552855,
     "end_time": "2023-07-01T23:36:37.690036",
     "exception": false,
     "start_time": "2023-07-01T23:36:34.137181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scaling - fit on training data only, transform both\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)  # Fit and transform training data\n",
    "x_test_scaled = scaler.transform(x_test)  # Only transform test data\n",
    "\n",
    "print(f\"Scaled training data shape: {x_train_scaled.shape}\")\n",
    "print(f\"Scaled test data shape: {x_test_scaled.shape}\")\n",
    "\n",
    "# Update variables\n",
    "x_train = x_train_scaled\n",
    "x_test = x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70319d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:39.801646Z",
     "iopub.status.busy": "2023-07-01T23:36:39.801261Z",
     "iopub.status.idle": "2023-07-01T23:36:39.810234Z",
     "shell.execute_reply": "2023-07-01T23:36:39.809271Z"
    },
    "papermill": {
     "duration": 1.07326,
     "end_time": "2023-07-01T23:36:39.812513",
     "exception": false,
     "start_time": "2023-07-01T23:36:38.739253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Callbacks with correct metric names\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model_no_leakage.h5', \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    factor=0.5,\n",
    "    min_lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11421989",
   "metadata": {
    "papermill": {
     "duration": 0.989157,
     "end_time": "2023-07-01T23:36:41.733745",
     "exception": false,
     "start_time": "2023-07-01T23:36:40.744588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Applying early stopping for all models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b560b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:43.656961Z",
     "iopub.status.busy": "2023-07-01T23:36:43.656568Z",
     "iopub.status.idle": "2023-07-01T23:36:43.661766Z",
     "shell.execute_reply": "2023-07-01T23:36:43.660819Z"
    },
    "papermill": {
     "duration": 1.004643,
     "end_time": "2023-07-01T23:36:43.664044",
     "exception": false,
     "start_time": "2023-07-01T23:36:42.659401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "model_checkpoint = ModelCheckpoint('best_model1_weights.h5', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea95cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:45.530400Z",
     "iopub.status.busy": "2023-07-01T23:36:45.529998Z",
     "iopub.status.idle": "2023-07-01T23:36:45.535539Z",
     "shell.execute_reply": "2023-07-01T23:36:45.534544Z"
    },
    "papermill": {
     "duration": 0.945059,
     "end_time": "2023-07-01T23:36:45.537699",
     "exception": false,
     "start_time": "2023-07-01T23:36:44.592640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix callback monitor parameter - use 'val_accuracy' not 'val_acc' for Keras 2.x\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',mode='auto',patience=5,restore_best_weights=True)\n",
    "lr_reduction=ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8918d",
   "metadata": {
    "papermill": {
     "duration": 0.979971,
     "end_time": "2023-07-01T23:36:57.179433",
     "exception": false,
     "start_time": "2023-07-01T23:36:56.199462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03406a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:36:59.041540Z",
     "iopub.status.busy": "2023-07-01T23:36:59.041155Z",
     "iopub.status.idle": "2023-07-01T23:36:59.049325Z",
     "shell.execute_reply": "2023-07-01T23:36:59.048350Z"
    },
    "papermill": {
     "duration": 0.943769,
     "end_time": "2023-07-01T23:36:59.051616",
     "exception": false,
     "start_time": "2023-07-01T23:36:58.107847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape for CNN (1D convolution)\n",
    "x_train_cnn = np.expand_dims(x_train, axis=2)\n",
    "x_test_cnn = np.expand_dims(x_test, axis=2)\n",
    "\n",
    "print(f\"CNN training data shape: {x_train_cnn.shape}\")\n",
    "print(f\"CNN test data shape: {x_test_cnn.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a0eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:37:01.039054Z",
     "iopub.status.busy": "2023-07-01T23:37:01.038409Z",
     "iopub.status.idle": "2023-07-01T23:37:03.907786Z",
     "shell.execute_reply": "2023-07-01T23:37:03.906743Z"
    },
    "papermill": {
     "duration": 3.802153,
     "end_time": "2023-07-01T23:37:03.910139",
     "exception": false,
     "start_time": "2023-07-01T23:37:00.107986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "\n",
    "# CNN Model with proper input shape\n",
    "model = tf.keras.Sequential([\n",
    "    # Input layer with correct shape\n",
    "    L.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu',\n",
    "             input_shape=(x_train_cnn.shape[1], 1)),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "    \n",
    "    L.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "    L.Dropout(0.2),\n",
    "    \n",
    "    L.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=3, strides=2, padding='same'),\n",
    "    \n",
    "    L.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=3, strides=2, padding='same'),\n",
    "    L.Dropout(0.2),\n",
    "    \n",
    "    L.Conv1D(64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=3, strides=2, padding='same'),\n",
    "    L.Dropout(0.3),\n",
    "    \n",
    "    L.Flatten(),\n",
    "    L.Dense(256, activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.Dropout(0.4),\n",
    "    L.Dense(128, activation='relu'),\n",
    "    L.Dropout(0.3),\n",
    "    L.Dense(y_train.shape[1], activation='softmax')  # Dynamic output size\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5127682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T23:37:05.849020Z",
     "iopub.status.busy": "2023-07-01T23:37:05.848037Z",
     "iopub.status.idle": "2023-07-02T01:06:31.138148Z",
     "shell.execute_reply": "2023-07-02T01:06:31.137062Z"
    },
    "papermill": {
     "duration": 5366.229128,
     "end_time": "2023-07-02T01:06:31.140985",
     "exception": false,
     "start_time": "2023-07-01T23:37:04.911857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model with leak-free data\n",
    "print(\"Training CNN model with NO DATA LEAKAGE...\")\n",
    "print(f\"Training on {x_train_cnn.shape[0]} samples\")\n",
    "print(f\"Validating on {x_test_cnn.shape[0]} samples\")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_cnn, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_test_cnn, y_test),\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, lr_reduction, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30a414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:06:37.824704Z",
     "iopub.status.busy": "2023-07-02T01:06:37.823869Z",
     "iopub.status.idle": "2023-07-02T01:06:45.762776Z",
     "shell.execute_reply": "2023-07-02T01:06:45.761796Z"
    },
    "papermill": {
     "duration": 11.286907,
     "end_time": "2023-07-02T01:06:45.765388",
     "exception": false,
     "start_time": "2023-07-02T01:06:34.478481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate model on leak-free test data\n",
    "test_accuracy = model.evaluate(x_test_cnn, y_test, verbose=0)[1]\n",
    "print(f\"Test Accuracy (NO DATA LEAKAGE): {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Plot training history\n",
    "epochs_range = range(len(history.history['accuracy']))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.plot(epochs_range, history.history['accuracy'], label='Training Accuracy')\n",
    "ax1.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy (No Data Leakage)')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Loss plot\n",
    "ax2.plot(epochs_range, history.history['loss'], label='Training Loss')\n",
    "ax2.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss (No Data Leakage)')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Best Validation Accuracy: {max(history.history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"This is a more realistic accuracy without data leakage!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93645cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:06:52.431730Z",
     "iopub.status.busy": "2023-07-02T01:06:52.431277Z",
     "iopub.status.idle": "2023-07-02T01:06:59.178818Z",
     "shell.execute_reply": "2023-07-02T01:06:59.177870Z"
    },
    "papermill": {
     "duration": 10.106852,
     "end_time": "2023-07-02T01:06:59.181770",
     "exception": false,
     "start_time": "2023-07-02T01:06:49.074918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate predictions on test data\n",
    "pred_test = model.predict(x_test_cnn)\n",
    "y_pred = onehot_encoder.inverse_transform(pred_test)\n",
    "y_test_labels = onehot_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Convert back to original labels\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred.flatten())\n",
    "y_test_original = label_encoder.inverse_transform(y_test_labels.flatten())\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted Labels': y_pred_original,\n",
    "    'Actual Labels': y_test_original\n",
    "})\n",
    "\n",
    "print(\"Sample predictions (NO DATA LEAKAGE):\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "print(f\"\\nPrediction accuracy verification:\")\n",
    "print(f\"Correct predictions: {sum(results_df['Predicted Labels'] == results_df['Actual Labels'])}\")\n",
    "print(f\"Total predictions: {len(results_df)}\")\n",
    "print(f\"Accuracy: {sum(results_df['Predicted Labels'] == results_df['Actual Labels'])/len(results_df)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea8fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:07:05.887969Z",
     "iopub.status.busy": "2023-07-02T01:07:05.887585Z",
     "iopub.status.idle": "2023-07-02T01:07:05.901494Z",
     "shell.execute_reply": "2023-07-02T01:07:05.900416Z"
    },
    "papermill": {
     "duration": 3.321128,
     "end_time": "2023-07-02T01:07:05.904053",
     "exception": false,
     "start_time": "2023-07-02T01:07:02.582925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb576d7",
   "metadata": {
    "papermill": {
     "duration": 3.347415,
     "end_time": "2023-07-02T01:07:12.581110",
     "exception": false,
     "start_time": "2023-07-02T01:07:09.233695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Some plots of multi_model\n",
    "______________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadcd00c",
   "metadata": {
    "papermill": {
     "duration": 3.383851,
     "end_time": "2023-07-02T01:08:20.093267",
     "exception": false,
     "start_time": "2023-07-02T01:08:16.709416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evalutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dc6ab",
   "metadata": {
    "papermill": {
     "duration": 3.291793,
     "end_time": "2023-07-02T01:08:26.678033",
     "exception": false,
     "start_time": "2023-07-02T01:08:23.386240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Results of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516b958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:08:33.386393Z",
     "iopub.status.busy": "2023-07-02T01:08:33.385890Z",
     "iopub.status.idle": "2023-07-02T01:08:34.743371Z",
     "shell.execute_reply": "2023-07-02T01:08:34.742306Z"
    },
    "papermill": {
     "duration": 4.720065,
     "end_time": "2023-07-02T01:08:34.746051",
     "exception": false,
     "start_time": "2023-07-02T01:08:30.025986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test0, y_pred0)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()\n",
    "print(classification_report(y_test0, y_pred0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb0ac2",
   "metadata": {
    "papermill": {
     "duration": 3.350496,
     "end_time": "2023-07-02T01:08:41.423335",
     "exception": false,
     "start_time": "2023-07-02T01:08:38.072839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd192ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:08:48.090710Z",
     "iopub.status.busy": "2023-07-02T01:08:48.089941Z",
     "iopub.status.idle": "2023-07-02T01:08:48.178237Z",
     "shell.execute_reply": "2023-07-02T01:08:48.176992Z"
    },
    "papermill": {
     "duration": 3.433255,
     "end_time": "2023-07-02T01:08:48.180589",
     "exception": false,
     "start_time": "2023-07-02T01:08:44.747334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPROVED MODEL SAVING - Consistent naming and complete saving\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "\n",
    "print(\"Saving model with consistent naming...\")\n",
    "\n",
    "# 1. Save the complete model (architecture + weights)\n",
    "model.save('complete_emotion_model.h5')\n",
    "print(\"‚úÖ Complete model saved as: complete_emotion_model.h5\")\n",
    "\n",
    "# 2. Save model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"CNN_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"‚úÖ Model architecture saved as: CNN_model.json\")\n",
    "\n",
    "# 3. Save weights with consistent naming (match the ModelCheckpoint callback)\n",
    "model.save_weights(\"best_model_no_leakage.h5\")\n",
    "print(\"‚úÖ Model weights saved as: best_model_no_leakage.h5\")\n",
    "\n",
    "# 4. Save preprocessing objects for deployment\n",
    "with open('scaler_final.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"‚úÖ Scaler saved as: scaler_final.pickle\")\n",
    "    \n",
    "with open('label_encoder_final.pickle', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(\"‚úÖ Label encoder saved as: label_encoder_final.pickle\")\n",
    "    \n",
    "with open('onehot_encoder_final.pickle', 'wb') as f:\n",
    "    pickle.dump(onehot_encoder, f)\n",
    "print(\"‚úÖ OneHot encoder saved as: onehot_encoder_final.pickle\")\n",
    "\n",
    "print(\"\\nüéâ MODEL SAVED SUCCESSFULLY!\")\n",
    "print(\"Files created for deployment:\")\n",
    "print(\"- complete_emotion_model.h5 (full model)\")\n",
    "print(\"- CNN_model.json (architecture)\")\n",
    "print(\"- best_model_no_leakage.h5 (weights)\")\n",
    "print(\"- scaler_final.pickle\")\n",
    "print(\"- label_encoder_final.pickle\") \n",
    "print(\"- onehot_encoder_final.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179cec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:08:54.843825Z",
     "iopub.status.busy": "2023-07-02T01:08:54.843430Z",
     "iopub.status.idle": "2023-07-02T01:08:55.085606Z",
     "shell.execute_reply": "2023-07-02T01:08:55.084539Z"
    },
    "papermill": {
     "duration": 3.576073,
     "end_time": "2023-07-02T01:08:55.088204",
     "exception": false,
     "start_time": "2023-07-02T01:08:51.512131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPROVED MODEL LOADING - Consistent naming\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "\n",
    "print(\"Loading model with consistent naming...\")\n",
    "\n",
    "# Load model architecture\n",
    "json_file = open('/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights with consistent naming (match the saved filename)\n",
    "loaded_model.load_weights(\"/kaggle/working/best_model_no_leakage.h5\")\n",
    "print(\"‚úÖ Loaded model from disk with consistent naming\")\n",
    "\n",
    "# Alternative: Load complete model directly\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model('/kaggle/working/complete_emotion_model.h5')\n",
    "# print(\"‚úÖ Loaded complete model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2a567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:09:01.774091Z",
     "iopub.status.busy": "2023-07-02T01:09:01.773675Z",
     "iopub.status.idle": "2023-07-02T01:09:09.719917Z",
     "shell.execute_reply": "2023-07-02T01:09:09.718683Z"
    },
    "papermill": {
     "duration": 11.322573,
     "end_time": "2023-07-02T01:09:09.722450",
     "exception": false,
     "start_time": "2023-07-02T01:08:58.399877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate loaded model with consistent variable names\n",
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_test_cnn, y_test)  # Use consistent variable names\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecd26a",
   "metadata": {
    "papermill": {
     "duration": 3.327979,
     "end_time": "2023-07-02T01:09:16.361282",
     "exception": false,
     "start_time": "2023-07-02T01:09:13.033303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving and Loading our Stnadrad Scaler and encoder\n",
    "* To save the StandardScaler object to use it later in a Flask API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265a5e6",
   "metadata": {
    "papermill": {
     "duration": 3.226626,
     "end_time": "2023-07-02T01:09:23.018548",
     "exception": false,
     "start_time": "2023-07-02T01:09:19.791922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9e6ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:09:29.785078Z",
     "iopub.status.busy": "2023-07-02T01:09:29.784637Z",
     "iopub.status.idle": "2023-07-02T01:09:29.795995Z",
     "shell.execute_reply": "2023-07-02T01:09:29.794985Z"
    },
    "papermill": {
     "duration": 3.36157,
     "end_time": "2023-07-02T01:09:29.798489",
     "exception": false,
     "start_time": "2023-07-02T01:09:26.436919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# IMPROVED SAVING - Consistent with final naming convention\n",
    "print(\"Saving preprocessors with consistent naming...\")\n",
    "\n",
    "# Save scaler with final naming\n",
    "with open('scaler_final.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"‚úÖ Scaler saved as: scaler_final.pickle\")\n",
    "\n",
    "# Save label encoder with final naming  \n",
    "with open('label_encoder_final.pickle', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(\"‚úÖ Label encoder saved as: label_encoder_final.pickle\")\n",
    "\n",
    "# Save onehot encoder with final naming\n",
    "with open('onehot_encoder_final.pickle', 'wb') as f:\n",
    "    pickle.dump(onehot_encoder, f)\n",
    "print(\"‚úÖ OneHot encoder saved as: onehot_encoder_final.pickle\")\n",
    "\n",
    "# Load them back to verify\n",
    "with open('scaler_final.pickle', 'rb') as f:\n",
    "    scaler_loaded = pickle.load(f)\n",
    "\n",
    "with open('label_encoder_final.pickle', 'rb') as f:\n",
    "    label_encoder_loaded = pickle.load(f)\n",
    "    \n",
    "with open('onehot_encoder_final.pickle', 'rb') as f:\n",
    "    onehot_encoder_loaded = pickle.load(f)\n",
    "\n",
    "print(\"‚úÖ All preprocessors saved and verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404881d0",
   "metadata": {
    "papermill": {
     "duration": 3.304143,
     "end_time": "2023-07-02T01:09:36.420228",
     "exception": false,
     "start_time": "2023-07-02T01:09:33.116085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test script\n",
    "* That can predict new record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e0f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:09:43.496151Z",
     "iopub.status.busy": "2023-07-02T01:09:43.495723Z",
     "iopub.status.idle": "2023-07-02T01:09:43.736759Z",
     "shell.execute_reply": "2023-07-02T01:09:43.735695Z"
    },
    "papermill": {
     "duration": 3.561734,
     "end_time": "2023-07-02T01:09:43.739090",
     "exception": false,
     "start_time": "2023-07-02T01:09:40.177356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPROVED TEST SCRIPT - Load model with consistent naming\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "\n",
    "print(\"Loading model for prediction with consistent naming...\")\n",
    "\n",
    "# Load model architecture\n",
    "json_file = open('/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights with consistent naming\n",
    "loaded_model.load_weights(\"/kaggle/working/best_model_no_leakage.h5\")\n",
    "print(\"‚úÖ Loaded model from disk for predictions\")\n",
    "\n",
    "# Compile the model for predictions\n",
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c40b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:09:50.448933Z",
     "iopub.status.busy": "2023-07-02T01:09:50.447867Z",
     "iopub.status.idle": "2023-07-02T01:09:50.459747Z",
     "shell.execute_reply": "2023-07-02T01:09:50.456054Z"
    },
    "papermill": {
     "duration": 3.423861,
     "end_time": "2023-07-02T01:09:50.462245",
     "exception": false,
     "start_time": "2023-07-02T01:09:47.038384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# IMPROVED LOADING - Load preprocessors with consistent naming\n",
    "print(\"Loading preprocessors with consistent naming...\")\n",
    "\n",
    "with open('/kaggle/working/scaler_final.pickle', 'rb') as f:\n",
    "    scaler_loaded = pickle.load(f)\n",
    "print(\"‚úÖ Scaler loaded\")\n",
    "\n",
    "with open('/kaggle/working/label_encoder_final.pickle', 'rb') as f:\n",
    "    label_encoder_loaded = pickle.load(f)\n",
    "print(\"‚úÖ Label encoder loaded\")\n",
    "    \n",
    "with open('/kaggle/working/onehot_encoder_final.pickle', 'rb') as f:\n",
    "    onehot_encoder_loaded = pickle.load(f)\n",
    "print(\"‚úÖ OneHot encoder loaded\")\n",
    "\n",
    "print(\"‚úÖ All preprocessors loaded successfully for predictions!\")\n",
    "\n",
    "# Use consistent variable names for predictions\n",
    "scaler2 = scaler_loaded\n",
    "encoder2 = onehot_encoder_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41740b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:09:57.091926Z",
     "iopub.status.busy": "2023-07-02T01:09:57.091541Z",
     "iopub.status.idle": "2023-07-02T01:09:57.096021Z",
     "shell.execute_reply": "2023-07-02T01:09:57.095074Z"
    },
    "papermill": {
     "duration": 3.324148,
     "end_time": "2023-07-02T01:09:57.098092",
     "exception": false,
     "start_time": "2023-07-02T01:09:53.773944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5cbe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:03.682060Z",
     "iopub.status.busy": "2023-07-02T01:10:03.681638Z",
     "iopub.status.idle": "2023-07-02T01:10:03.692718Z",
     "shell.execute_reply": "2023-07-02T01:10:03.691779Z"
    },
    "papermill": {
     "duration": 3.226462,
     "end_time": "2023-07-02T01:10:03.694994",
     "exception": false,
     "start_time": "2023-07-02T01:10:00.468532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPROVED FEATURE EXTRACTION - Match training features exactly\n",
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(y=data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    \"\"\"Extract features matching exactly what was used during training\"\"\"\n",
    "    result=np.array([])\n",
    "    \n",
    "    # Add spectral features to match training (IMPORTANT!)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=data, sr=sr, hop_length=hop_length)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=data, sr=sr, hop_length=hop_length)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=data, sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length),\n",
    "                      np.squeeze(spectral_centroid),  # Added for consistency\n",
    "                      np.squeeze(spectral_bandwidth),  # Added for consistency  \n",
    "                      np.squeeze(spectral_rolloff)     # Added for consistency\n",
    "                     ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5213414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:10.912039Z",
     "iopub.status.busy": "2023-07-02T01:10:10.910972Z",
     "iopub.status.idle": "2023-07-02T01:10:10.917847Z",
     "shell.execute_reply": "2023-07-02T01:10:10.916821Z"
    },
    "papermill": {
     "duration": 3.811843,
     "end_time": "2023-07-02T01:10:10.920064",
     "exception": false,
     "start_time": "2023-07-02T01:10:07.108221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPROVED PREDICTION FUNCTION - Fixed feature dimensions and consistent naming\n",
    "def get_predict_feat(path):\n",
    "    \"\"\"Extract features for prediction with correct dimensions\"\"\"\n",
    "    d, s_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    res = extract_features(d)  # Now includes spectral features\n",
    "    result = np.array(res)\n",
    "    \n",
    "    # Check the actual feature dimensions from training\n",
    "    print(f\"Extracted features shape: {result.shape}\")\n",
    "    \n",
    "    # Reshape to match training data format\n",
    "    result = np.reshape(result, newshape=(1, -1))  # Dynamic reshaping\n",
    "    print(f\"Reshaped features: {result.shape}\")\n",
    "    \n",
    "    # Scale using the same scaler from training\n",
    "    i_result = scaler2.transform(result)\n",
    "    \n",
    "    # Expand dims for CNN input\n",
    "    final_result = np.expand_dims(i_result, axis=2)\n",
    "    print(f\"Final features for CNN: {final_result.shape}\")\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756b53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:17.527551Z",
     "iopub.status.busy": "2023-07-02T01:10:17.526892Z",
     "iopub.status.idle": "2023-07-02T01:10:17.659078Z",
     "shell.execute_reply": "2023-07-02T01:10:17.657902Z"
    },
    "papermill": {
     "duration": 3.446326,
     "end_time": "2023-07-02T01:10:17.663670",
     "exception": false,
     "start_time": "2023-07-02T01:10:14.217344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res=get_predict_feat(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav\")\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267176b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:24.440288Z",
     "iopub.status.busy": "2023-07-02T01:10:24.439876Z",
     "iopub.status.idle": "2023-07-02T01:10:24.446389Z",
     "shell.execute_reply": "2023-07-02T01:10:24.445254Z"
    },
    "papermill": {
     "duration": 3.328888,
     "end_time": "2023-07-02T01:10:24.448710",
     "exception": false,
     "start_time": "2023-07-02T01:10:21.119822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPROVED PREDICTION FUNCTION - Proper emotion mapping\n",
    "def prediction(path1):\n",
    "    \"\"\"Predict emotion from audio file path\"\"\"\n",
    "    try:\n",
    "        # Extract features\n",
    "        res = get_predict_feat(path1)\n",
    "        \n",
    "        # Make prediction\n",
    "        predictions = loaded_model.predict(res)\n",
    "        print(f\"Raw predictions shape: {predictions.shape}\")\n",
    "        print(f\"Raw predictions: {predictions}\")\n",
    "        \n",
    "        # Convert one-hot back to label\n",
    "        y_pred = encoder2.inverse_transform(predictions)\n",
    "        predicted_emotion = y_pred[0][0]\n",
    "        \n",
    "        # Get confidence scores\n",
    "        confidence = np.max(predictions) * 100\n",
    "        \n",
    "        print(f\"üéØ Predicted Emotion: {predicted_emotion}\")\n",
    "        print(f\"üéØ Confidence: {confidence:.2f}%\")\n",
    "        \n",
    "        return predicted_emotion, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in prediction: {str(e)}\")\n",
    "        return None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59059745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:31.114782Z",
     "iopub.status.busy": "2023-07-02T01:10:31.114346Z",
     "iopub.status.idle": "2023-07-02T01:10:31.542811Z",
     "shell.execute_reply": "2023-07-02T01:10:31.541767Z"
    },
    "papermill": {
     "duration": 3.801792,
     "end_time": "2023-07-02T01:10:31.545224",
     "exception": false,
     "start_time": "2023-07-02T01:10:27.743432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-01-01-01-01-02.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc4d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:38.234168Z",
     "iopub.status.busy": "2023-07-02T01:10:38.233750Z",
     "iopub.status.idle": "2023-07-02T01:10:38.435697Z",
     "shell.execute_reply": "2023-07-02T01:10:38.434086Z"
    },
    "papermill": {
     "duration": 3.548648,
     "end_time": "2023-07-02T01:10:38.439834",
     "exception": false,
     "start_time": "2023-07-02T01:10:34.891186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-01-01-01-01-01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393d005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:45.576625Z",
     "iopub.status.busy": "2023-07-02T01:10:45.576250Z",
     "iopub.status.idle": "2023-07-02T01:10:45.791285Z",
     "shell.execute_reply": "2023-07-02T01:10:45.789635Z"
    },
    "papermill": {
     "duration": 3.455134,
     "end_time": "2023-07-02T01:10:45.795347",
     "exception": false,
     "start_time": "2023-07-02T01:10:42.340213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-05-01-02-02-01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253a29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:52.662396Z",
     "iopub.status.busy": "2023-07-02T01:10:52.661981Z",
     "iopub.status.idle": "2023-07-02T01:10:52.871664Z",
     "shell.execute_reply": "2023-07-02T01:10:52.870313Z"
    },
    "papermill": {
     "duration": 3.573345,
     "end_time": "2023-07-02T01:10:52.876166",
     "exception": false,
     "start_time": "2023-07-02T01:10:49.302821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_21/03-01-04-02-02-02-21.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520bfed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:10:59.648571Z",
     "iopub.status.busy": "2023-07-02T01:10:59.647983Z",
     "iopub.status.idle": "2023-07-02T01:10:59.877550Z",
     "shell.execute_reply": "2023-07-02T01:10:59.876163Z"
    },
    "papermill": {
     "duration": 3.591759,
     "end_time": "2023-07-02T01:10:59.881354",
     "exception": false,
     "start_time": "2023-07-02T01:10:56.289595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-06-01-02-02-02.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5e3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:11:06.534989Z",
     "iopub.status.busy": "2023-07-02T01:11:06.534602Z",
     "iopub.status.idle": "2023-07-02T01:11:06.732325Z",
     "shell.execute_reply": "2023-07-02T01:11:06.729112Z"
    },
    "papermill": {
     "duration": 3.507734,
     "end_time": "2023-07-02T01:11:06.735878",
     "exception": false,
     "start_time": "2023-07-02T01:11:03.228144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-08-01-01-01-01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9410be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T01:11:13.892805Z",
     "iopub.status.busy": "2023-07-02T01:11:13.892416Z",
     "iopub.status.idle": "2023-07-02T01:11:14.077255Z",
     "shell.execute_reply": "2023-07-02T01:11:14.075820Z"
    },
    "papermill": {
     "duration": 3.936253,
     "end_time": "2023-07-02T01:11:14.081020",
     "exception": false,
     "start_time": "2023-07-02T01:11:10.144767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11598.328512,
   "end_time": "2023-07-02T01:11:20.401611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-01T21:58:02.073099",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
